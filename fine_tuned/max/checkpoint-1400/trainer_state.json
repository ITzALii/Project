{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 48.284444444444446,
  "eval_steps": 500,
  "global_step": 1400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 0.7228350639343262,
      "learning_rate": 0.0001987142857142857,
      "loss": 3.5671,
      "step": 10
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 0.5028296113014221,
      "learning_rate": 0.0001972857142857143,
      "loss": 1.3051,
      "step": 20
    },
    {
      "epoch": 1.0355555555555556,
      "grad_norm": 0.6378334164619446,
      "learning_rate": 0.00019585714285714288,
      "loss": 1.0464,
      "step": 30
    },
    {
      "epoch": 1.3911111111111112,
      "grad_norm": 0.22475379705429077,
      "learning_rate": 0.00019442857142857144,
      "loss": 0.7691,
      "step": 40
    },
    {
      "epoch": 1.7466666666666666,
      "grad_norm": 0.17505280673503876,
      "learning_rate": 0.000193,
      "loss": 0.7,
      "step": 50
    },
    {
      "epoch": 2.071111111111111,
      "grad_norm": 0.17935028672218323,
      "learning_rate": 0.0001915714285714286,
      "loss": 0.6914,
      "step": 60
    },
    {
      "epoch": 2.4266666666666667,
      "grad_norm": 0.1378641426563263,
      "learning_rate": 0.00019014285714285715,
      "loss": 0.6736,
      "step": 70
    },
    {
      "epoch": 2.7822222222222224,
      "grad_norm": 0.12787339091300964,
      "learning_rate": 0.00018871428571428574,
      "loss": 0.6703,
      "step": 80
    },
    {
      "epoch": 3.1066666666666665,
      "grad_norm": 0.17403602600097656,
      "learning_rate": 0.0001872857142857143,
      "loss": 0.6657,
      "step": 90
    },
    {
      "epoch": 3.462222222222222,
      "grad_norm": 0.1787641942501068,
      "learning_rate": 0.00018585714285714286,
      "loss": 0.6461,
      "step": 100
    },
    {
      "epoch": 3.8177777777777777,
      "grad_norm": 0.15744781494140625,
      "learning_rate": 0.00018442857142857144,
      "loss": 0.6396,
      "step": 110
    },
    {
      "epoch": 4.142222222222222,
      "grad_norm": 0.2561951279640198,
      "learning_rate": 0.000183,
      "loss": 0.6334,
      "step": 120
    },
    {
      "epoch": 4.497777777777777,
      "grad_norm": 0.20627757906913757,
      "learning_rate": 0.00018157142857142856,
      "loss": 0.6234,
      "step": 130
    },
    {
      "epoch": 4.8533333333333335,
      "grad_norm": 0.19311517477035522,
      "learning_rate": 0.00018014285714285715,
      "loss": 0.6236,
      "step": 140
    },
    {
      "epoch": 5.177777777777778,
      "grad_norm": 0.19502617418766022,
      "learning_rate": 0.0001787142857142857,
      "loss": 0.6186,
      "step": 150
    },
    {
      "epoch": 5.533333333333333,
      "grad_norm": 0.22657589614391327,
      "learning_rate": 0.0001772857142857143,
      "loss": 0.6132,
      "step": 160
    },
    {
      "epoch": 5.888888888888889,
      "grad_norm": 0.2335873395204544,
      "learning_rate": 0.00017585714285714288,
      "loss": 0.5984,
      "step": 170
    },
    {
      "epoch": 6.213333333333333,
      "grad_norm": 0.30676138401031494,
      "learning_rate": 0.00017442857142857142,
      "loss": 0.6109,
      "step": 180
    },
    {
      "epoch": 6.568888888888889,
      "grad_norm": 0.23569151759147644,
      "learning_rate": 0.000173,
      "loss": 0.5923,
      "step": 190
    },
    {
      "epoch": 6.924444444444444,
      "grad_norm": 0.2844531834125519,
      "learning_rate": 0.0001715714285714286,
      "loss": 0.5917,
      "step": 200
    },
    {
      "epoch": 7.248888888888889,
      "grad_norm": 0.3355942666530609,
      "learning_rate": 0.00017014285714285715,
      "loss": 0.5834,
      "step": 210
    },
    {
      "epoch": 7.604444444444445,
      "grad_norm": 0.31662294268608093,
      "learning_rate": 0.0001687142857142857,
      "loss": 0.5748,
      "step": 220
    },
    {
      "epoch": 7.96,
      "grad_norm": 0.28052064776420593,
      "learning_rate": 0.0001672857142857143,
      "loss": 0.5851,
      "step": 230
    },
    {
      "epoch": 8.284444444444444,
      "grad_norm": 0.3239542543888092,
      "learning_rate": 0.00016585714285714286,
      "loss": 0.5683,
      "step": 240
    },
    {
      "epoch": 8.64,
      "grad_norm": 0.3083399832248688,
      "learning_rate": 0.00016442857142857144,
      "loss": 0.5639,
      "step": 250
    },
    {
      "epoch": 8.995555555555555,
      "grad_norm": 0.3442241847515106,
      "learning_rate": 0.000163,
      "loss": 0.5642,
      "step": 260
    },
    {
      "epoch": 9.32,
      "grad_norm": 0.35317450761795044,
      "learning_rate": 0.00016157142857142856,
      "loss": 0.5525,
      "step": 270
    },
    {
      "epoch": 9.675555555555556,
      "grad_norm": 0.396363228559494,
      "learning_rate": 0.00016014285714285715,
      "loss": 0.5509,
      "step": 280
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.8689447641372681,
      "learning_rate": 0.00015871428571428574,
      "loss": 0.5357,
      "step": 290
    },
    {
      "epoch": 10.355555555555556,
      "grad_norm": 0.3646530508995056,
      "learning_rate": 0.0001572857142857143,
      "loss": 0.5289,
      "step": 300
    },
    {
      "epoch": 10.71111111111111,
      "grad_norm": 0.39784708619117737,
      "learning_rate": 0.00015585714285714286,
      "loss": 0.5234,
      "step": 310
    },
    {
      "epoch": 11.035555555555556,
      "grad_norm": 0.5094227194786072,
      "learning_rate": 0.00015442857142857145,
      "loss": 0.52,
      "step": 320
    },
    {
      "epoch": 11.391111111111112,
      "grad_norm": 0.4401153326034546,
      "learning_rate": 0.000153,
      "loss": 0.5192,
      "step": 330
    },
    {
      "epoch": 11.746666666666666,
      "grad_norm": 0.4658929705619812,
      "learning_rate": 0.0001515714285714286,
      "loss": 0.5141,
      "step": 340
    },
    {
      "epoch": 12.071111111111112,
      "grad_norm": 0.46841639280319214,
      "learning_rate": 0.00015014285714285715,
      "loss": 0.5047,
      "step": 350
    },
    {
      "epoch": 12.426666666666666,
      "grad_norm": 0.48219195008277893,
      "learning_rate": 0.0001487142857142857,
      "loss": 0.4966,
      "step": 360
    },
    {
      "epoch": 12.782222222222222,
      "grad_norm": 0.5138813853263855,
      "learning_rate": 0.0001472857142857143,
      "loss": 0.4924,
      "step": 370
    },
    {
      "epoch": 13.106666666666667,
      "grad_norm": 0.6012911200523376,
      "learning_rate": 0.00014585714285714286,
      "loss": 0.4954,
      "step": 380
    },
    {
      "epoch": 13.462222222222222,
      "grad_norm": 0.5424712300300598,
      "learning_rate": 0.00014442857142857145,
      "loss": 0.4777,
      "step": 390
    },
    {
      "epoch": 13.817777777777778,
      "grad_norm": 0.5124982595443726,
      "learning_rate": 0.000143,
      "loss": 0.4687,
      "step": 400
    },
    {
      "epoch": 14.142222222222221,
      "grad_norm": 0.5997040867805481,
      "learning_rate": 0.00014157142857142857,
      "loss": 0.4593,
      "step": 410
    },
    {
      "epoch": 14.497777777777777,
      "grad_norm": 0.5747262835502625,
      "learning_rate": 0.00014014285714285715,
      "loss": 0.4561,
      "step": 420
    },
    {
      "epoch": 14.853333333333333,
      "grad_norm": 0.6054720282554626,
      "learning_rate": 0.00013871428571428574,
      "loss": 0.4481,
      "step": 430
    },
    {
      "epoch": 15.177777777777777,
      "grad_norm": 0.6093978881835938,
      "learning_rate": 0.00013728571428571427,
      "loss": 0.4457,
      "step": 440
    },
    {
      "epoch": 15.533333333333333,
      "grad_norm": 0.6456937789916992,
      "learning_rate": 0.00013585714285714286,
      "loss": 0.4281,
      "step": 450
    },
    {
      "epoch": 15.88888888888889,
      "grad_norm": 0.6563977003097534,
      "learning_rate": 0.00013442857142857145,
      "loss": 0.4237,
      "step": 460
    },
    {
      "epoch": 16.213333333333335,
      "grad_norm": 0.6802191734313965,
      "learning_rate": 0.000133,
      "loss": 0.4305,
      "step": 470
    },
    {
      "epoch": 16.56888888888889,
      "grad_norm": 0.6840404868125916,
      "learning_rate": 0.00013157142857142857,
      "loss": 0.4006,
      "step": 480
    },
    {
      "epoch": 16.924444444444443,
      "grad_norm": 0.6476678848266602,
      "learning_rate": 0.00013014285714285715,
      "loss": 0.4091,
      "step": 490
    },
    {
      "epoch": 17.24888888888889,
      "grad_norm": 0.6548181176185608,
      "learning_rate": 0.00012871428571428571,
      "loss": 0.3832,
      "step": 500
    },
    {
      "epoch": 17.604444444444443,
      "grad_norm": 0.7235162258148193,
      "learning_rate": 0.0001272857142857143,
      "loss": 0.3949,
      "step": 510
    },
    {
      "epoch": 17.96,
      "grad_norm": 0.731924295425415,
      "learning_rate": 0.00012585714285714286,
      "loss": 0.3952,
      "step": 520
    },
    {
      "epoch": 18.284444444444443,
      "grad_norm": 0.6771544814109802,
      "learning_rate": 0.00012442857142857142,
      "loss": 0.3708,
      "step": 530
    },
    {
      "epoch": 18.64,
      "grad_norm": 0.84515380859375,
      "learning_rate": 0.000123,
      "loss": 0.381,
      "step": 540
    },
    {
      "epoch": 18.995555555555555,
      "grad_norm": 0.6832098364830017,
      "learning_rate": 0.00012157142857142858,
      "loss": 0.3752,
      "step": 550
    },
    {
      "epoch": 19.32,
      "grad_norm": 0.8144809603691101,
      "learning_rate": 0.00012014285714285716,
      "loss": 0.356,
      "step": 560
    },
    {
      "epoch": 19.675555555555555,
      "grad_norm": 0.7984926104545593,
      "learning_rate": 0.00011871428571428572,
      "loss": 0.3638,
      "step": 570
    },
    {
      "epoch": 20.0,
      "grad_norm": 1.6766722202301025,
      "learning_rate": 0.00011728571428571429,
      "loss": 0.3643,
      "step": 580
    },
    {
      "epoch": 20.355555555555554,
      "grad_norm": 0.7884547710418701,
      "learning_rate": 0.00011585714285714286,
      "loss": 0.3492,
      "step": 590
    },
    {
      "epoch": 20.711111111111112,
      "grad_norm": 0.814612090587616,
      "learning_rate": 0.00011442857142857144,
      "loss": 0.3535,
      "step": 600
    },
    {
      "epoch": 21.035555555555554,
      "grad_norm": 0.7423420548439026,
      "learning_rate": 0.000113,
      "loss": 0.3464,
      "step": 610
    },
    {
      "epoch": 21.391111111111112,
      "grad_norm": 0.7809712290763855,
      "learning_rate": 0.00011157142857142857,
      "loss": 0.3381,
      "step": 620
    },
    {
      "epoch": 21.746666666666666,
      "grad_norm": 0.7947952747344971,
      "learning_rate": 0.00011014285714285714,
      "loss": 0.3433,
      "step": 630
    },
    {
      "epoch": 22.07111111111111,
      "grad_norm": 0.8565216660499573,
      "learning_rate": 0.00010871428571428573,
      "loss": 0.3278,
      "step": 640
    },
    {
      "epoch": 22.426666666666666,
      "grad_norm": 0.9359766840934753,
      "learning_rate": 0.0001072857142857143,
      "loss": 0.3284,
      "step": 650
    },
    {
      "epoch": 22.782222222222224,
      "grad_norm": 0.9059786200523376,
      "learning_rate": 0.00010585714285714285,
      "loss": 0.3289,
      "step": 660
    },
    {
      "epoch": 23.106666666666666,
      "grad_norm": 0.8654384613037109,
      "learning_rate": 0.00010442857142857144,
      "loss": 0.3286,
      "step": 670
    },
    {
      "epoch": 23.462222222222223,
      "grad_norm": 0.8733087778091431,
      "learning_rate": 0.00010300000000000001,
      "loss": 0.3194,
      "step": 680
    },
    {
      "epoch": 23.817777777777778,
      "grad_norm": 0.8834174275398254,
      "learning_rate": 0.00010157142857142858,
      "loss": 0.318,
      "step": 690
    },
    {
      "epoch": 24.142222222222223,
      "grad_norm": 0.8554961085319519,
      "learning_rate": 0.00010014285714285714,
      "loss": 0.3119,
      "step": 700
    },
    {
      "epoch": 24.497777777777777,
      "grad_norm": 0.973049521446228,
      "learning_rate": 9.871428571428572e-05,
      "loss": 0.3091,
      "step": 710
    },
    {
      "epoch": 24.85333333333333,
      "grad_norm": 0.8718094825744629,
      "learning_rate": 9.728571428571429e-05,
      "loss": 0.3104,
      "step": 720
    },
    {
      "epoch": 25.177777777777777,
      "grad_norm": 0.8007548451423645,
      "learning_rate": 9.585714285714285e-05,
      "loss": 0.3019,
      "step": 730
    },
    {
      "epoch": 25.533333333333335,
      "grad_norm": 0.8722373843193054,
      "learning_rate": 9.442857142857144e-05,
      "loss": 0.2968,
      "step": 740
    },
    {
      "epoch": 25.88888888888889,
      "grad_norm": 0.9790546298027039,
      "learning_rate": 9.300000000000001e-05,
      "loss": 0.3044,
      "step": 750
    },
    {
      "epoch": 26.213333333333335,
      "grad_norm": 0.8913894295692444,
      "learning_rate": 9.157142857142857e-05,
      "loss": 0.2943,
      "step": 760
    },
    {
      "epoch": 26.56888888888889,
      "grad_norm": 0.8531484007835388,
      "learning_rate": 9.014285714285716e-05,
      "loss": 0.2931,
      "step": 770
    },
    {
      "epoch": 26.924444444444443,
      "grad_norm": 0.8950648307800293,
      "learning_rate": 8.871428571428572e-05,
      "loss": 0.2924,
      "step": 780
    },
    {
      "epoch": 27.24888888888889,
      "grad_norm": 0.8963084816932678,
      "learning_rate": 8.728571428571429e-05,
      "loss": 0.2806,
      "step": 790
    },
    {
      "epoch": 27.604444444444443,
      "grad_norm": 0.8860510587692261,
      "learning_rate": 8.585714285714286e-05,
      "loss": 0.2864,
      "step": 800
    },
    {
      "epoch": 27.96,
      "grad_norm": 1.078309178352356,
      "learning_rate": 8.442857142857144e-05,
      "loss": 0.2841,
      "step": 810
    },
    {
      "epoch": 28.284444444444443,
      "grad_norm": 0.9359416961669922,
      "learning_rate": 8.3e-05,
      "loss": 0.2771,
      "step": 820
    },
    {
      "epoch": 28.64,
      "grad_norm": 0.9741198420524597,
      "learning_rate": 8.157142857142857e-05,
      "loss": 0.2728,
      "step": 830
    },
    {
      "epoch": 28.995555555555555,
      "grad_norm": 0.916312575340271,
      "learning_rate": 8.014285714285715e-05,
      "loss": 0.2804,
      "step": 840
    },
    {
      "epoch": 29.32,
      "grad_norm": 0.9261234402656555,
      "learning_rate": 7.871428571428572e-05,
      "loss": 0.2702,
      "step": 850
    },
    {
      "epoch": 29.675555555555555,
      "grad_norm": 0.9261578917503357,
      "learning_rate": 7.728571428571429e-05,
      "loss": 0.2691,
      "step": 860
    },
    {
      "epoch": 30.0,
      "grad_norm": 2.0563650131225586,
      "learning_rate": 7.585714285714287e-05,
      "loss": 0.2674,
      "step": 870
    },
    {
      "epoch": 30.355555555555554,
      "grad_norm": 0.9151681661605835,
      "learning_rate": 7.442857142857144e-05,
      "loss": 0.2651,
      "step": 880
    },
    {
      "epoch": 30.711111111111112,
      "grad_norm": 0.9567314982414246,
      "learning_rate": 7.3e-05,
      "loss": 0.2621,
      "step": 890
    },
    {
      "epoch": 31.035555555555554,
      "grad_norm": 0.9994205236434937,
      "learning_rate": 7.157142857142857e-05,
      "loss": 0.2602,
      "step": 900
    },
    {
      "epoch": 31.391111111111112,
      "grad_norm": 0.9803642630577087,
      "learning_rate": 7.014285714285715e-05,
      "loss": 0.2574,
      "step": 910
    },
    {
      "epoch": 31.746666666666666,
      "grad_norm": 1.0654582977294922,
      "learning_rate": 6.871428571428572e-05,
      "loss": 0.2564,
      "step": 920
    },
    {
      "epoch": 32.07111111111111,
      "grad_norm": 0.9664954543113708,
      "learning_rate": 6.728571428571428e-05,
      "loss": 0.2574,
      "step": 930
    },
    {
      "epoch": 32.42666666666667,
      "grad_norm": 0.8911192417144775,
      "learning_rate": 6.585714285714287e-05,
      "loss": 0.2527,
      "step": 940
    },
    {
      "epoch": 32.782222222222224,
      "grad_norm": 0.9600405097007751,
      "learning_rate": 6.442857142857143e-05,
      "loss": 0.2521,
      "step": 950
    },
    {
      "epoch": 33.10666666666667,
      "grad_norm": 1.0430251359939575,
      "learning_rate": 6.3e-05,
      "loss": 0.243,
      "step": 960
    },
    {
      "epoch": 33.46222222222222,
      "grad_norm": 0.9873050451278687,
      "learning_rate": 6.157142857142857e-05,
      "loss": 0.2431,
      "step": 970
    },
    {
      "epoch": 33.81777777777778,
      "grad_norm": 0.958243191242218,
      "learning_rate": 6.014285714285715e-05,
      "loss": 0.2499,
      "step": 980
    },
    {
      "epoch": 34.14222222222222,
      "grad_norm": 0.9152231812477112,
      "learning_rate": 5.871428571428572e-05,
      "loss": 0.2372,
      "step": 990
    },
    {
      "epoch": 34.49777777777778,
      "grad_norm": 0.9006428718566895,
      "learning_rate": 5.728571428571429e-05,
      "loss": 0.2392,
      "step": 1000
    },
    {
      "epoch": 34.85333333333333,
      "grad_norm": 1.0230135917663574,
      "learning_rate": 5.585714285714286e-05,
      "loss": 0.2436,
      "step": 1010
    },
    {
      "epoch": 35.17777777777778,
      "grad_norm": 0.9667364954948425,
      "learning_rate": 5.442857142857143e-05,
      "loss": 0.2399,
      "step": 1020
    },
    {
      "epoch": 35.53333333333333,
      "grad_norm": 0.9661146402359009,
      "learning_rate": 5.300000000000001e-05,
      "loss": 0.2342,
      "step": 1030
    },
    {
      "epoch": 35.888888888888886,
      "grad_norm": 1.0367463827133179,
      "learning_rate": 5.157142857142857e-05,
      "loss": 0.2375,
      "step": 1040
    },
    {
      "epoch": 36.21333333333333,
      "grad_norm": 0.9898033142089844,
      "learning_rate": 5.014285714285715e-05,
      "loss": 0.2378,
      "step": 1050
    },
    {
      "epoch": 36.568888888888885,
      "grad_norm": 0.9938201904296875,
      "learning_rate": 4.8714285714285714e-05,
      "loss": 0.2332,
      "step": 1060
    },
    {
      "epoch": 36.92444444444445,
      "grad_norm": 0.921958327293396,
      "learning_rate": 4.728571428571429e-05,
      "loss": 0.2308,
      "step": 1070
    },
    {
      "epoch": 37.24888888888889,
      "grad_norm": 0.9591642022132874,
      "learning_rate": 4.585714285714286e-05,
      "loss": 0.2229,
      "step": 1080
    },
    {
      "epoch": 37.60444444444445,
      "grad_norm": 1.0262068510055542,
      "learning_rate": 4.442857142857143e-05,
      "loss": 0.2307,
      "step": 1090
    },
    {
      "epoch": 37.96,
      "grad_norm": 0.9657887816429138,
      "learning_rate": 4.3e-05,
      "loss": 0.2311,
      "step": 1100
    },
    {
      "epoch": 38.284444444444446,
      "grad_norm": 0.9583168029785156,
      "learning_rate": 4.1571428571428575e-05,
      "loss": 0.2274,
      "step": 1110
    },
    {
      "epoch": 38.64,
      "grad_norm": 0.9772495627403259,
      "learning_rate": 4.014285714285714e-05,
      "loss": 0.224,
      "step": 1120
    },
    {
      "epoch": 38.995555555555555,
      "grad_norm": 1.0784507989883423,
      "learning_rate": 3.8714285714285715e-05,
      "loss": 0.2248,
      "step": 1130
    },
    {
      "epoch": 39.32,
      "grad_norm": 0.920052170753479,
      "learning_rate": 3.728571428571428e-05,
      "loss": 0.2236,
      "step": 1140
    },
    {
      "epoch": 39.675555555555555,
      "grad_norm": 1.0341041088104248,
      "learning_rate": 3.585714285714286e-05,
      "loss": 0.2225,
      "step": 1150
    },
    {
      "epoch": 40.0,
      "grad_norm": 2.390150785446167,
      "learning_rate": 3.442857142857143e-05,
      "loss": 0.2258,
      "step": 1160
    },
    {
      "epoch": 40.355555555555554,
      "grad_norm": 0.9307324886322021,
      "learning_rate": 3.3e-05,
      "loss": 0.2173,
      "step": 1170
    },
    {
      "epoch": 40.71111111111111,
      "grad_norm": 1.00568425655365,
      "learning_rate": 3.1571428571428576e-05,
      "loss": 0.2231,
      "step": 1180
    },
    {
      "epoch": 41.035555555555554,
      "grad_norm": 0.884143054485321,
      "learning_rate": 3.0142857142857146e-05,
      "loss": 0.2162,
      "step": 1190
    },
    {
      "epoch": 41.39111111111111,
      "grad_norm": 1.0661611557006836,
      "learning_rate": 2.8714285714285716e-05,
      "loss": 0.2116,
      "step": 1200
    },
    {
      "epoch": 41.74666666666667,
      "grad_norm": 0.9894981384277344,
      "learning_rate": 2.7285714285714286e-05,
      "loss": 0.2183,
      "step": 1210
    },
    {
      "epoch": 42.07111111111111,
      "grad_norm": 0.9404433965682983,
      "learning_rate": 2.5857142857142856e-05,
      "loss": 0.2153,
      "step": 1220
    },
    {
      "epoch": 42.42666666666667,
      "grad_norm": 1.0096371173858643,
      "learning_rate": 2.442857142857143e-05,
      "loss": 0.2159,
      "step": 1230
    },
    {
      "epoch": 42.782222222222224,
      "grad_norm": 1.0911712646484375,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 0.2139,
      "step": 1240
    },
    {
      "epoch": 43.10666666666667,
      "grad_norm": 0.9430543780326843,
      "learning_rate": 2.1571428571428574e-05,
      "loss": 0.2139,
      "step": 1250
    },
    {
      "epoch": 43.46222222222222,
      "grad_norm": 0.9661388397216797,
      "learning_rate": 2.0142857142857144e-05,
      "loss": 0.2149,
      "step": 1260
    },
    {
      "epoch": 43.81777777777778,
      "grad_norm": 0.9616662263870239,
      "learning_rate": 1.8714285714285714e-05,
      "loss": 0.2109,
      "step": 1270
    },
    {
      "epoch": 44.14222222222222,
      "grad_norm": 0.9327418804168701,
      "learning_rate": 1.7285714285714287e-05,
      "loss": 0.2121,
      "step": 1280
    },
    {
      "epoch": 44.49777777777778,
      "grad_norm": 1.0190067291259766,
      "learning_rate": 1.5857142857142857e-05,
      "loss": 0.2084,
      "step": 1290
    },
    {
      "epoch": 44.85333333333333,
      "grad_norm": 1.0512741804122925,
      "learning_rate": 1.442857142857143e-05,
      "loss": 0.21,
      "step": 1300
    },
    {
      "epoch": 45.17777777777778,
      "grad_norm": 1.0405021905899048,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 0.2089,
      "step": 1310
    },
    {
      "epoch": 45.53333333333333,
      "grad_norm": 0.9644596576690674,
      "learning_rate": 1.1571428571428573e-05,
      "loss": 0.205,
      "step": 1320
    },
    {
      "epoch": 45.888888888888886,
      "grad_norm": 0.9431892037391663,
      "learning_rate": 1.0142857142857143e-05,
      "loss": 0.2092,
      "step": 1330
    },
    {
      "epoch": 46.21333333333333,
      "grad_norm": 0.9538711905479431,
      "learning_rate": 8.714285714285715e-06,
      "loss": 0.2051,
      "step": 1340
    },
    {
      "epoch": 46.568888888888885,
      "grad_norm": 0.9738419651985168,
      "learning_rate": 7.285714285714286e-06,
      "loss": 0.2087,
      "step": 1350
    },
    {
      "epoch": 46.92444444444445,
      "grad_norm": 0.9289257526397705,
      "learning_rate": 5.857142857142857e-06,
      "loss": 0.2048,
      "step": 1360
    },
    {
      "epoch": 47.24888888888889,
      "grad_norm": 0.894763708114624,
      "learning_rate": 4.428571428571428e-06,
      "loss": 0.2057,
      "step": 1370
    },
    {
      "epoch": 47.60444444444445,
      "grad_norm": 0.9515565037727356,
      "learning_rate": 3e-06,
      "loss": 0.2087,
      "step": 1380
    },
    {
      "epoch": 47.96,
      "grad_norm": 0.9582394361495972,
      "learning_rate": 1.5714285714285717e-06,
      "loss": 0.2045,
      "step": 1390
    },
    {
      "epoch": 48.284444444444446,
      "grad_norm": 0.894201397895813,
      "learning_rate": 1.4285714285714287e-07,
      "loss": 0.2022,
      "step": 1400
    }
  ],
  "logging_steps": 10,
  "max_steps": 1400,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.677734872274698e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
